{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Competition - Google Colab Version\n",
    "\n",
    "This notebook combines everything you need to compete in the CIFAR-10 image classification competition!\n",
    "\n",
    "**Goal:** Build a CNN that achieves the highest accuracy on the augmented test set.\n",
    "\n",
    "**What's in this notebook:**\n",
    "1. Data exploration of CIFAR-10\n",
    "2. Model architecture (SimpleCNN)\n",
    "3. Training pipeline with configurable hyperparameters\n",
    "4. Submission generation for Kaggle\n",
    "\n",
    "**Workflow:**\n",
    "1. Run Part 1 to explore the data\n",
    "2. (Optional) Modify the model architecture in Part 2\n",
    "3. (Optional) Add data augmentations in Part 3\n",
    "4. Run Part 4 to train the model\n",
    "5. Upload test files from Kaggle and run Part 5 to generate submission.csv\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Libraries and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (if needed)\n",
    "!pip install torch torchvision tqdm pandas matplotlib pillow -q\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 1: Data Exploration\n",
    "\n",
    "Let's explore the CIFAR-10 dataset to understand what we're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Load CIFAR-10 Dataset\n",
    "\n",
    "CIFAR-10 is a classic image classification dataset:\n",
    "- 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- Same tiny 32Ã—32 pixel images\n",
    "- 5,000 training images per class (50,000 total)\n",
    "- 1,000 test images per class (10,000 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset with basic transforms\n",
    "basic_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset_explore = datasets.CIFAR10(root='./data', train=True, download=True, transform=basic_transform)\n",
    "test_dataset_explore = datasets.CIFAR10(root='./data', train=False, download=True, transform=basic_transform)\n",
    "\n",
    "# CIFAR-10 class names\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f'Training images: {len(train_dataset_explore)}')\n",
    "print(f'Test images: {len(test_dataset_explore)}')\n",
    "print(f'Number of classes: {len(classes)}')\n",
    "print(f'Classes: {classes}')\n",
    "print(f'Image shape: {train_dataset_explore[0][0].shape}')  # (3, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Visualize Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from the training set\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = train_dataset_explore[np.random.randint(len(train_dataset_explore))]\n",
    "    ax.imshow(img.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "    ax.set_title(f'{classes[label]}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Random CIFAR-10 Training Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nCIFAR-10 has 10 different classes!')\n",
    "print('The competition will test your model on AUGMENTED versions of these images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class in training set\n",
    "train_labels = [label for _, label in train_dataset_explore]\n",
    "label_counts = Counter(train_labels)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(classes)), [label_counts[i] for i in range(len(classes))], \n",
    "        color='steelblue', alpha=0.7, tick_label=classes)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('CIFAR-10 Training Set - Class Distribution')\n",
    "plt.axhline(y=5000, color='red', linestyle='--', label='Expected: 5,000 per class')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Total classes: {len(label_counts)}')\n",
    "print(f'Images per class: {label_counts[0]}')\n",
    "print('Dataset is balanced!' if len(set(label_counts.values())) == 1 else 'Dataset is imbalanced!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4: Image Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 random images and compute statistics\n",
    "sample_images = [train_dataset_explore[i][0] for i in np.random.choice(len(train_dataset_explore), 1000, replace=False)]\n",
    "sample_tensor = torch.stack(sample_images)\n",
    "\n",
    "# Compute mean and std per channel\n",
    "mean = sample_tensor.mean(dim=[0, 2, 3])\n",
    "std = sample_tensor.std(dim=[0, 2, 3])\n",
    "\n",
    "print('Pixel Statistics (from 1000 random images):')\n",
    "print(f'Mean (R, G, B): {mean.numpy()}')\n",
    "print(f'Std  (R, G, B): {std.numpy()}')\n",
    "print('\\nNote: Values are in [0, 1] range after ToTensor()')\n",
    "print('These statistics can be used for normalization in your transforms!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 2: Model Architecture\n",
    "\n",
    "Define the CNN model. You can modify this architecture to improve performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN baseline for CIFAR-10\n",
    "\n",
    "    This is a basic architecture to get you started.\n",
    "    Current architecture achieves ~50-60% accuracy.\n",
    "\n",
    "    TODO: Improve this architecture! Some ideas:\n",
    "    - Add more convolutional layers\n",
    "    - Add BatchNorm layers after Conv layers\n",
    "    - Try different filter sizes\n",
    "    - Experiment with different pooling strategies\n",
    "    - Add residual connections (ResNet-style)\n",
    "    - Try different activation functions\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 32x32x3 -> 32x32x32\n",
    "            nn.ReLU(inplace=True),\n",
    "            # TODO: Add BatchNorm here? nn.BatchNorm2d(32)\n",
    "            nn.MaxPool2d(2),  # 32x32x32 -> 16x16x32\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 16x16x32 -> 16x16x64\n",
    "            nn.ReLU(inplace=True),\n",
    "            # TODO: Add BatchNorm here?\n",
    "            nn.MaxPool2d(2),  # 16x16x64 -> 8x8x64\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # 8x8x64 -> 8x8x128\n",
    "            nn.ReLU(inplace=True),\n",
    "            # TODO: Add BatchNorm here?\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # 8x8x128 -> 1x1x128\n",
    "\n",
    "            # TODO: Add more blocks? More layers usually = better performance!\n",
    "        )\n",
    "\n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # TODO: Experiment with different dropout rates?\n",
    "            nn.Linear(128, num_classes)\n",
    "            # TODO: Add more fully connected layers?\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "print('SimpleCNN model defined!')\n",
    "print('You can modify the architecture above to improve performance.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 3: Data Transforms and Augmentation\n",
    "\n",
    "**THIS IS KEY TO SUCCESS!** The competition test set has augmentations (noise, blur, color shifts, etc.).\n",
    "\n",
    "You MUST train with similar augmentations to generalize well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(augment=False):\n",
    "    \"\"\"\n",
    "    Get data transforms for training and testing\n",
    "\n",
    "    Args:\n",
    "        augment: If True, apply data augmentation (for training)\n",
    "                 If False, only normalize (for testing)\n",
    "\n",
    "    Returns:\n",
    "        Composed transforms\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        # TODO: Add MORE augmentations here! This is KEY to better performance!\n",
    "        # The test set has augmentations (noise, blur, color shifts, etc.)\n",
    "        # Train with similar augmentations to generalize better!\n",
    "        #\n",
    "        # Suggestions:\n",
    "        # - transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3)\n",
    "        # - transforms.RandomRotation(15)\n",
    "        # - transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n",
    "        # - transforms.RandomGrayscale(p=0.1)\n",
    "        # - Add noise? Blur? (use custom transforms)\n",
    "        #\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            # TODO: Add more augmentations here!\n",
    "\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    else:\n",
    "        # No augmentation for testing\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "print('Data transforms defined!')\n",
    "print('Modify get_transforms() above to add more augmentations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 4: Training\n",
    "\n",
    "Configure hyperparameters and train the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Configure Training Hyperparameters\n",
    "\n",
    "Modify these to experiment with different settings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CONFIGURATION - Modify these!\n",
    "EPOCHS = 10  # TODO: Try 20-30 epochs for better performance\n",
    "LEARNING_RATE = 0.001  # TODO: Experiment with 0.0001, 0.001, 0.01\n",
    "BATCH_SIZE = 128  # TODO: Try 64, 128, 256 (smaller batch size if out of memory)\n",
    "OPTIMIZER_TYPE = 'adam'  # Options: 'adam', 'sgd', 'adamw'\n",
    "USE_SCHEDULER = False  # TODO: Try True to use learning rate scheduler\n",
    "\n",
    "print('='*60)\n",
    "print('TRAINING CONFIGURATION')\n",
    "print('='*60)\n",
    "print(f'Device: {device}')\n",
    "print(f'Epochs: {EPOCHS}')\n",
    "print(f'Learning Rate: {LEARNING_RATE}')\n",
    "print(f'Batch Size: {BATCH_SIZE}')\n",
    "print(f'Optimizer: {OPTIMIZER_TYPE}')\n",
    "print(f'LR Scheduler: {USE_SCHEDULER}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset with augmentation\n",
    "print('Loading CIFAR-10 dataset...')\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True,\n",
    "                                 transform=get_transforms(augment=True))\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True,\n",
    "                                transform=get_transforms(augment=False))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Training images: {len(train_dataset)}')\n",
    "print(f'Test images: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Setup Model, Optimizer, and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "print(f'Model: SimpleCNN')\n",
    "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer selection\n",
    "if OPTIMIZER_TYPE == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif OPTIMIZER_TYPE == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, nesterov=True)\n",
    "elif OPTIMIZER_TYPE == 'adamw':\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "else:\n",
    "    raise ValueError(f'Unknown optimizer: {OPTIMIZER_TYPE}')\n",
    "\n",
    "print(f'Optimizer: {optimizer.__class__.__name__}')\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = None\n",
    "if USE_SCHEDULER:\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    print(f'LR Scheduler: StepLR (step_size=10, gamma=0.1)')\n",
    "else:\n",
    "    print('LR Scheduler: None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4: Define Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track metrics\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print('Training functions defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5: Train the Model!\n",
    "\n",
    "This will take a few minutes. Watch the accuracy improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('TRAINING START')\n",
    "print('='*60)\n",
    "print()\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "    # Validate\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f'Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%')\n",
    "    print(f'Test  - Loss: {test_loss:.4f}, Acc: {test_acc:.2f}%')\n",
    "\n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'âœ“ Saved best model (acc: {best_acc:.2f}%)')\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "        print(f'Learning rate: {scheduler.get_last_lr()[0]:.6f}')\n",
    "\n",
    "    print()\n",
    "\n",
    "print('='*60)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*60)\n",
    "print(f'Best test accuracy: {best_acc:.2f}%')\n",
    "print('Model saved as best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 5: Generate Kaggle Submission\n",
    "\n",
    "Upload your test files from Kaggle and generate submission.csv!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1: Upload Test Files from Kaggle\n",
    "\n",
    "**Instructions:**\n",
    "1. Download `test.csv` and `test_images.zip` from the Kaggle competition page\n",
    "2. Upload them to this Colab notebook using the file browser on the left\n",
    "3. Unzip the test images by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip test images (if test_images.zip exists)\n",
    "import zipfile\n",
    "\n",
    "if os.path.exists('test_images.zip'):\n",
    "    print('Unzipping test_images.zip...')\n",
    "    with zipfile.ZipFile('test_images.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    print('âœ“ Test images extracted to test_images/')\n",
    "else:\n",
    "    print('âŒ test_images.zip not found!')\n",
    "    print('   Please upload test_images.zip from Kaggle.')\n",
    "\n",
    "# Check if test.csv exists\n",
    "if os.path.exists('test.csv'):\n",
    "    print('âœ“ test.csv found!')\n",
    "else:\n",
    "    print('âŒ test.csv not found!')\n",
    "    print('   Please upload test.csv from Kaggle.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2: Generate Submission File\n",
    "\n",
    "This will create `submission.csv` that you can upload to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, test_csv='test.csv', test_images_dir='test_images',\n",
    "                       output_csv='submission.csv', device='cpu'):\n",
    "    \"\"\"\n",
    "    Generate Kaggle submission file\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        test_csv: Path to test.csv (contains image IDs)\n",
    "        test_images_dir: Directory containing test images\n",
    "        output_csv: Path to save submission\n",
    "        device: Device to run inference on\n",
    "    \"\"\"\n",
    "    print('\\n' + '='*60)\n",
    "    print('GENERATING KAGGLE SUBMISSION')\n",
    "    print('='*60)\n",
    "\n",
    "    # Check if test files exist\n",
    "    if not os.path.exists(test_csv):\n",
    "        print(f'âŒ {test_csv} not found!')\n",
    "        print('   Download test.csv from Kaggle to generate submission.')\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(test_images_dir):\n",
    "        print(f'âŒ {test_images_dir}/ not found!')\n",
    "        print('   Download and unzip test_images.zip from Kaggle.')\n",
    "        return\n",
    "\n",
    "    # Load test image IDs\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    print(f'Found {len(test_df)} test images')\n",
    "\n",
    "    # Get transforms (no augmentation for testing!)\n",
    "    test_transform = get_transforms(augment=False)\n",
    "\n",
    "    # Generate predictions\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_id in tqdm(test_df['id'], desc='Predicting'):\n",
    "            # Load image - format ID with leading zeros to match filename\n",
    "            img_filename = f'{str(img_id).zfill(5)}.png'\n",
    "            img_path = os.path.join(test_images_dir, img_filename)\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f'Warning: {img_path} not found, skipping...')\n",
    "                continue\n",
    "\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = test_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "            # Predict\n",
    "            output = model(img_tensor)\n",
    "            pred_class = output.argmax(1).item()\n",
    "\n",
    "            predictions.append({\n",
    "                'id': img_id,\n",
    "                'label': pred_class\n",
    "            })\n",
    "\n",
    "    # Save submission\n",
    "    submission_df = pd.DataFrame(predictions)\n",
    "    submission_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f'\\nâœ… Submission saved to {output_csv}')\n",
    "    print(f'   Total predictions: {len(submission_df)}')\n",
    "    print('\\nPreview:')\n",
    "    print(submission_df.head(10))\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'ðŸ“¤ Download {output_csv} and upload to Kaggle!')\n",
    "    print('='*60 + '\\n')\n",
    "\n",
    "\n",
    "# Load best model and generate submission\n",
    "print('Loading best model...')\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "print('âœ“ Best model loaded!')\n",
    "\n",
    "# Generate submission\n",
    "generate_submission(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3: Download Submission File\n",
    "\n",
    "If submission.csv was generated successfully, download it using the file browser on the left and upload to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if submission.csv exists\n",
    "if os.path.exists('submission.csv'):\n",
    "    print('âœ… submission.csv ready for download!')\n",
    "    print('\\nNext steps:')\n",
    "    print('1. Download submission.csv using the file browser on the left')\n",
    "    print('2. Go to the Kaggle competition page')\n",
    "    print('3. Click \"Submit Predictions\"')\n",
    "    print('4. Upload submission.csv')\n",
    "    print('5. Check your score on the leaderboard!')\n",
    "    print('\\nGood luck! ðŸš€')\n",
    "else:\n",
    "    print('âŒ submission.csv not found!')\n",
    "    print('   Make sure you uploaded test.csv and test_images.zip from Kaggle.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tips for Improving Your Score ðŸ’¡\n",
    "\n",
    "## 1. Data Augmentation is KEY! â­â­â­\n",
    "The competition test set has heavy augmentations (noise, blur, color shifts). You MUST train with similar augmentations!\n",
    "\n",
    "**Try adding to `get_transforms()`:**\n",
    "```python\n",
    "transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1)\n",
    "transforms.RandomRotation(15)\n",
    "transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n",
    "transforms.RandomGrayscale(p=0.1)\n",
    "transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "```\n",
    "\n",
    "## 2. Improve Model Architecture\n",
    "- Add more convolutional blocks\n",
    "- Add BatchNorm after each Conv layer: `nn.BatchNorm2d(channels)`\n",
    "- Try deeper networks (4-6 blocks)\n",
    "- Increase number of filters (256, 512)\n",
    "\n",
    "## 3. Train Longer\n",
    "- 10 epochs is just a baseline\n",
    "- Try 20-30 epochs for better results\n",
    "- Monitor for overfitting (train acc >> test acc)\n",
    "\n",
    "## 4. Experiment with Hyperparameters\n",
    "- Learning rate: Try 0.0001, 0.001, 0.01\n",
    "- Batch size: Try 64, 128, 256\n",
    "- Optimizer: Try 'adam', 'sgd', 'adamw'\n",
    "- Use learning rate scheduler: `USE_SCHEDULER = True`\n",
    "\n",
    "## 5. Monitor Overfitting\n",
    "- If training accuracy >> test accuracy â†’ overfitting!\n",
    "- Solutions:\n",
    "  - Add more data augmentation\n",
    "  - Increase dropout\n",
    "  - Train for fewer epochs\n",
    "  - Use weight decay (AdamW)\n",
    "\n",
    "---\n",
    "\n",
    "Good luck with your competition! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
